# meta_diffusion
Python project detecting music features of an audio  track and a video. As output it produces bash script ready to be executed in a stable diffusion enviroment (https://github.com/CompVis/stable-diffusion) in order to produce an "allucinated" version of the input video music-reactive to the audio track given as input.
